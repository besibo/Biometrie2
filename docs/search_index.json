[
["index.html", "Travaux Pratiques de Biométrie 2 1 Introduction 1.1 Objectifs 1.2 Organisation", " Travaux Pratiques de Biométrie 2 Benoît Simon-Bouhet 2018-09-20 1 Introduction 1.1 Objectifs Ce livre contient l’ensemble du matériel (contenus, exemples, exercices…) nécessaire à la réalisation des travaux pratiques de biométrie 2. Ces travaux pratiques ont essentiellement 3 objectifs : Vous faire (re)découvrir les logiciels R et Rstudio dans lesquels vous allez passer beaucoup de temps en L3 puis en master. Si vous choisissez une spécialité de master qui implique de traiter des données (c’est-à-dire à peu près toutes les spécialités !) et /ou de communiquer des résultats d’analyses statistiques, alors R et RStudio devraient être les logiciels vers lesquels vous vous tournerez naturellement. Vous faire prendre conscience de l’importance des visualisations graphiques : d’une part, pour comprendre à quoi ressemblent les données en votre possession, d’autre part, pour vous permettre de formuler des hypothèses pertinentes et intéressantes concernant les systèmes que vous étudiez, et enfin, pour communiquer efficacement vos trouvailles à un public qui ne connait pas vos données aussi bien que vous (cela inclut évidemment vos enseignants à l’issue de vos stages). Les données que vous serez amenés à traiter lors de vos stages, ou plus tard, lorsque vous serez en poste, ont souvent été acquises à grands frais, et au prix d’efforts importants. Il est donc de votre responsabilité d’en tirer le maximum. Et ça commence toujours (ou presque), par la réalisation de visualisations graphiques parlantes. Vous apprendre comment calculer des statistiques descriptives simples, sur plusieurs types de variables, afin de vous mettre dans les meilleures conditions possible pour aborder d’une part les cours de biométrie 3 du second semestre, et d’autre part les comptes-rendus de TP que vous aurez à produire dans d’autres EC. Vos enseigants attendent de vous la plus grande rigueur lorsque vous analysez et présentez des résultats d’analyses statistiques. Ces TP ont pour objectifs de vous fournir les bases nécessaires pour satisfaire ce niveau d’exigence. 1.2 Organisation Les séances de travaux pratiques de biométrie 2 durent 1h30 et ont lieu en salle informatique du Pôle Communication Multimédia Réseaux (PCM). Seules 6 heures de TP sont prévues dans la maquette, soit 4 séances de TP. C’est très peu ! En fait, c’est très insuffisant pour couvrir correctement la totalité du contenu de cet enseignement. C’est la raison pour laquelle chacune des 3 premières séances de TP est suivie d’une séance de TEA de 90 minutes. Au début de chaque séance de TP, j’indiquerai un objectif que vous devriez être en mesure d’atteindre en l’espace de 3 heures. Certains iront probablement plus vite et d’autres plus lentement. Lors des séances de TP, je serai disponible pour répondre à chacune de vos questions. À l’issue des 90 minutes de TP, vous changerez de salle (toujours au PCM) et les 90 minutes de TEA commenceront. Pendant le TEA, vous devrez continuer la lecture de ce livre et terminer les exercices demandés. Les exercices devront être déposés sur l’ENT à l’issue de chaque séance de TEA, qu’ils soient terminés ou non. S’ils ne sont pas terminés à l’issue des TEA, vous êtes vivement encourragés à les terminer en dehors des heures de cours. En effet, une correction rapide sera faite lors de la séance de travaux pratiques suivante et nous n’auront que très peu de temps à consacrer à ces corrections. Si vous n’y avez pas sérieusement réfléchi en amont, cela ne vous servira absolument à rien. Pour apprendre à utiliser un logiciel comme R, il faut en effet faire les choses soi-même, “mettre les mains dans le cambouis”, se confronter à la difficulté, ne pas avoir peur des messages d’erreurs (il faut d’ailleurs apprendre à les déchiffrer pour comprendre d’où viennent les problèmes), essayer maintes fois, se tromper beaucoup, recommencer, et surtout, ne pas se décourager. Même si ce livre est conçu pour vous faciliter la tâche, l’apprentissage de R est souvent perçu comme une lutte. Mais quand ça fonctionne enfin, c’est extrêmement gratifiant et il n’existe pas à l’heure actuelle de meilleur logiciel pour analyser des données et produire des graphiques de qualité. Vous pouvez me croire sur parôle : j’utilise ce logiciel presque quotidiennement depuis près de 15 ans. Je m’efforcerai de passer 1 ou 2 fois auprès de vous lors des séances de TEA afin de vous débloquer en cas de problème majeur. Vous pouvez aussi me contacter par email. Toutefois, ce document est fait pour vous permettre d’avancer en autonomie. L’expérience montre que la plupart du temps, il suffit de lire correctement pour obtenir la réponse à ses questions. Je vous encourage également à vous entraider : c’est très formateur pour celui qui explique, et celui qui rencontre une difficulté a plus de chance de comprendre si c’est quelqu’un d’autre qui lui explique plutôt que la personne qui a rédigé les instructions mal comprises. Enfin, les exercices demandés ne seront pas notés, mais tout ce que nous voyons en TP devra être acquis le jour de l’examen. Utilisez donc le temps du TEA pour vous préparer au mieux. L’apprentissage prend du temps, donc autant s’y mettre sérieusement dès maintenant. "],
["bases.html", "2 R et RStudio : les bases 2.1 Que sont R et RStudio 2.2 Comment exécuter du code R ? 2.3 Les packages additionels 2.4 Exercices", " 2 R et RStudio : les bases Avant de commencer à explorer des données dans R, il y a plusieurs concepts de clé qu’il faut comprendre premier lieu : Que sont R et RStudio ? Comment s’y prend-on pour coder dans R ? Que sont les “packages” ? Si vous pensez être déjà à l’aise avec ces concepts, lisez attentivement ce chapitre et faites les exercices demandés. Cela vous rafraîchira probablement la mémoire, et il n’est pas impossible que vous appreniez une chose ou deux au passage. Une bonne maîtrise des éléments présentés dans ce chapitre est un effet nécessaire pour aborder sereinement la section 3 ci-dessous, qui présente quelques jeux de données que nous explorerons en détail au cours de ces séances de TP qui viennent. Ce chapitre est en grande partie basé sur les 3 ressources suivantes que je vous encourage à consulter si vous souhaitez obtenir plus de détails : L’ouvrage intitulé ModernDive, de Chester Ismay et Albert Y. Kim. Une bonne partie de cet ouvrage est très largement inspirée de cet ouvrage. C’est en anglais, mais c’est un très bon texte d’introduction aux statistiques sous R et RStudio. L’ouvrage intitulé Getting used to R, RStudio, and R Markdown de Chester Ismay, comprend des podcasts (en anglais toujours) que vous pouvez suivre en apprenant. Les tutoriels en ligne de DataCamp. DataCamp est une plateforme de e-learning accessible depuis n’importe quel navigateur internet dont la priorité est l’enseignement des “data sciences”. Leurs tutoriels vous aideront à apprendre certains des concepts de développés dans ce livre. Avant d’aller plus loin, rendez-vous sur le site de DataCamp et créez vous un compte gratuit. 2.1 Que sont R et RStudio Pour l’ensemble des TP de biométrie 2, j’attends de vous que vous utilisez R via RStudio. Les utilisateurs novices confondent souvent les deux. Pour tenter une analogie simple : R est le moteur d’une voiture RStudio est l’habitacle, le tableau de bord, les pédales Si vous n’avez pas de moteur, vous n’irez nulle part. En revanche, un moteur sans tableau de bord est difficile à manœuvrer. Il est en effet beaucoup plus simple de faire avancer une voiture depuis l’habitacle, plutôt qu’en actionnant à la main les cables et leviers du moteur. En l’occurence, R est un langage de programmation capable de produire des graphiques et de réaliser des analyses statistiques, des plus simples au plus complexes. RStudio est un “emballage” qui rend l’utilisation de R plus aisée. RStudio est ce qu’on appelle un IDE : Itegrated Development Environment. On peut utiliser R sans RStudio, mais c’est nettement plus compliqué, nettement moins pratique. 2.1.1 Installation de R et RStudio Si vous travaillez exclusivement sur les ordinateurs de l’Université, vous pouvez passer cette section. Si vous souhaitez utiliser R et RStudio sur votre ordinateur personnel, alors suivez le guide ! Avant tout, vous devez télécharger et installer R et RStudio, dans cet ordre : Téléchargez et installez R Note : vous devez installer ce logiciel en premier Cliquez sur le lien de telechargement qui correspond à votre système d’exploitation, puis, sur “base”, et suivez les instructions Téléchargez et installez R Cliquez sur “Download RStudio Desktop” Choisissez la version gratuite et cliquez sur le lien de télechargement qui correspond à votre système d’exploitation. Pour plus de détails sur la façon de procéder, vous pouvez consulter cette vidéo sur le site de DataCamp. Il est possible que vous deviez créer un compte (gratuit) pour accéder à la vidéo. 2.1.2 Utiliser R depuis RStudio Puisqu’il est beaucoup plus facile d’utiliser Rstudio pour interagir avec R, nous utiliserons exclusivement l’interface de RStudio. Après l’installation des 2 logiciels, vous disposez de 2 nouveaux logiciels sur votre ordinateur. RStudio ne peut fonctionner sans R, mais nous travaillerons exclusivement dans RStudio : R: Ne pas ouvrir ceci RStudio: ouvrir ça ! À l’université, vous trouverez RStudio dans le menu Windows. Quand vous ouvrez RStudio pour la première fois, vous devriez obtenir une fenêtre qui ressemble à ceci : Regardez cette vidéo DataCamp pour découvrir les différents panneaux de l’application, en particulier la Console dans laquelle nous executerons très bientôt du code R 2.2 Comment exécuter du code R ? Maintenant que vous avez configuré R et RStudio, vous vous demandez probablement “OK. Maintenant, comment utiliser R ?” La première chose à noter est que, contrairement à d’autres logiciels comme Excel, STATA ou SAS qui fournissent des interfaces où tout se fait en cliquant avec sa souris, R est un langage interprété, ce qui signifie que vous devez entrer des commandes R écrites en code R. C’est-à-dire que vous devez programmer en R (j’utilise les termes “coder” et “programmer” de manière interchangeable dans ce livre). Il n’est pas nécessaire d’être un programmeur pour utiliser R. Néamnoins il existe un ensemble de concepts de programmation de base que les utilisateurs R doivent comprendre. Par conséquent, bien que ce livre ne soit pas un livre sur la programmation, vous en apprendrez juste assez sur ces concepts de programmation de base nécessaires pour explorer et analyser efficacement des données. 2.2.1 La console La façon la plus simle d’interagir avec RStudio (mais pas du tout la meilleure !) consiste à taper directement des commandes que R pourra comprendre dans la Console. Cliquez dans la console (après le symbole &gt;) et tapez ceci, sans oublier de valider en tapant sur la touche Entrée : 3 + 8 [1] 11 Félicitations, vous venez de taper votre première instruction R : vous savez maintenant faire une addition ! 2.2.2 Le répertoire de travail La première commande que vous devriez connaître quand vous travaillez dans R ou RStudio est la suivante : getwd() Si vous tapez cette commande dans la console, RStudio doit vous afficher un emplacement sur votre ordinateur. Cet emplacement est appelé “Répertoire de travail”, ou “Working Directory” en anglais (getwd() est l’abbréviation de “Get Working Directory”). Ce répertoire de travail est important : c’est là que seront stockés les tableaux et graphiques que vous déciderez de sauvegarder. C’est là aussi que vous sauvegarderez vos scripts (voir plus bas) qui vous permettront de garder la trace de votre travail et de le reprendre là où vous l’aviez laissé la dernière fois. Enfin, lorsque vous souhaiterez importer des tableaux de données contenus dans des fichiers externes (par exemple, des fichiers Excel), c’est également dans ce répertoire que R tentera de trouver vos données. Avant d’aller plus loin je vous conseille donc vivement de : Créer un nouveau dossier intitulé “Biometrie” sur votre espace personnel (généralement, sur le disque “W:” des ordinateurs de l’Université) Indiquez à RStudio que vous souhaitez travailler dans ce nouveau répertoire de travail. Pour cela vous avez 3 solutions au choix : Dans RStudio, cliquez dans le menu “Session &gt; Set Working Directory &gt; Choose Directory…” puis naviguez jusqu’au dossier que vous venez de créer Dans le panneau “Files”, naviguez jusqu’au dossier “Biometrie” que vous venez de créer, puis cliquez sur le bouton “More &gt; Set As Working Directory” En ligne de commande, dans la console, utilisez la fonction setwd() pour spécifier le chemin de votre nouveau dossier, par exemple : # Attention à bien respecter les majuscules et à utiliser les guillemets. setwd(&quot;W:/Biometrie&quot;) Il ne vous reste plus qu’à vérifier que le changement a bien été pris en compte en tapant à nouveau getwd() dans la console. Attention, vous devez vous assurer d’être dans le bon répertoire de travil à chaque nouvelle session ! 2.2.3 Les scripts Taper du code directement dans la console est probablement la pire façon de travailler dans RStudio. Cela est parfois utile pour faire un rapide calcul, ou pour vérifier qu’une commande fonctionne correctement. Mais la plupart du temps, vous devriez taper vos commandes dans un script. Un script est un fichier au format “texte brut” (cela signifie qu’il n’y a pas de mise en forme et que ce fichier peut-être ouvert par n’importe quel éditeur de texte, y compris les plus simples comme le bloc notes de Windows), dans lequel vous pouvez taper : des instructions qui seront comprises par R comme si vous les tapiez directement dans la console des lignes de commentaires, qui doivent obligatoirement commencer par le symbole #. Les avantages de travailler dans un script sont nombreux : Vous pouvez sauvegarder votre script à tout moment (vous devriez prendre l’habitude de le sauvegarder très régulièrement). Vous gardez ainsi la trace de toutes les commandes que vous avez tapées. Vous pouvez aisément partager votre script pour collaborer avec vos collègues de promo et enseignants. Vous pouvez documenter votre démarche et les différentes étapes de vos analyses. Vous devez ajouter autant de commentaires que possible. Cela permettra à vos collaborateurs de comprendre ce que vous avez fait. Et cela vous permettra de comprendre ce que vous avez fait il y a 6 mois quand vous vous re-plongerez dans vos analyses dans quelques temps. Si votre démarche vous paraît cohérente maintenant, il n’est en effet pas garanti que vous rappellerez de chaque détail dans 6 mois ou 6 ans. Un script bien structuré et clair permet de rendre vos analyses répétables. Si vous passer 15 heures à analyser un tableau de données précis, il vous suffira de quelques secondes pour analyser un nouveau jeu de données similaires : vous n’aurez que quelques lignes à modifier dans votre script original pour l’appliquer à de nouvelles données. Vous pouvez créer un script en cliquant dans le menu “File &gt; New File &gt; R Script”. Un nouveau panneau s’ouvre dans l’application. Pensez à sauvegarder immédiatement votre nouveau script. Il faut pour cela lui donner un nom. Vous noterez que par défaut, RStudio propose d’enregistrer votre script dans votre répertoire de travail. À partir de maintenant, vous ne devriez plus taper de commande directement dans la console. Tapez systématiquement vos commandes dans un script et sauvegardez-le régulièrement. Pour exécuter les commandes du script dans la console, il suffit de placer le curseur sur la ligne contenant la commande et de presser les touches ctrl + enter (ou command + enter sous macOS). Si un message d’erreur s’affiche dans la console, c’est que votre instruction était erronée. Modifiez la directement dans votre script et pressez à nouveau les touches ctrl + enter (ou command + enter sous macOS) pour tenter à nouveau votre chance. Idéalement, votre script ne devrait contenir que des commandes qui fonctionnent et des commentaires expliquant à quoi servent ces commandes. À la fin de chaque séance de TEA, vous devrez déposer sur l’ENT le script que vous avez créé durant la séance. Ce script devra porter votre nom de famille et se terminer par l’extension .R. Ainsi, si Jean-Claude Van Damme faisait des statistiques, il devrait déposer sur l’ENT un fichier intitulé VanDamme.R à la fin de chaque séance de TEA. Ci-dessous, un exemple de script # Penser à installer le package ggplot2 si besoin install.packages(&#39;ggplot2&#39;) # Chargement du package library(ggplot2) # Mise en méoire des données de qualité de l&#39;air à New-York de mai à septembre # 1973 data(airquality) # Affichage des premières lignes du tableau de données head(airquality) # Quelle est la structure de ce tableau ? str(airquality) # Réalisation d&#39;un graphique présentant la relation entre la concentration en # ozone atmosphérique en ppb et la température en degrés Farenheit ggplot(data = airquality, mapping = aes(x = Temp, y = Ozone)) + geom_point() + geom_smooth(method = &quot;loess&quot;) # On constate une augmentation importante de la concentration d&#39;ozone pour des # températures supérieures à 75ºF Même si vous ne comprenez pas encore les commandes qui figurent dans ce script (ça viendra !), voici ce que vous devez en retenir : Le script contient plus de lignes de commentaires que de commandes R Chaque étape de l’analyse est décrite en détail On peut ajouter des commentaires afin de décrire les résultats Seules les commandes pertinentes et qui fonctionnent ont été conservées dans ce script Chaque ligne de commentaire commence par #. Il est ainsi possible de conserver certaines commandes R dans le script, “pour mémoire”, sans pour autant qu’elle ne soient exécutées. C’est le cas pour la ligne # install.packages(&quot;ggplot2&quot;). Si j’éxécute ce script dans la console de RStudio (en sélectionnant toutes les lignes et en pressant les touches ctrl+enter ou command+enter sous macOS), voilà ce qui est produit : Ozone Solar.R Wind Temp Month Day 1 41 190 7.4 67 5 1 2 36 118 8.0 72 5 2 3 12 149 12.6 74 5 3 4 18 313 11.5 62 5 4 5 NA NA 14.3 56 5 5 6 28 NA 14.9 66 5 6 &#39;data.frame&#39;: 153 obs. of 6 variables: $ Ozone : int 41 36 12 18 NA 28 23 19 8 NA ... $ Solar.R: int 190 118 149 313 NA NA 299 99 19 194 ... $ Wind : num 7.4 8 12.6 11.5 14.3 14.9 8.6 13.8 20.1 8.6 ... $ Temp : int 67 72 74 62 56 66 65 59 61 69 ... $ Month : int 5 5 5 5 5 5 5 5 5 5 ... $ Day : int 1 2 3 4 5 6 7 8 9 10 ... 2.2.4 Concepts de base en programmation et terminologie Pour vous présenter les concepts de base et la terminologie de la programmation dont nous aurons besoin dans R, vous allez suivre les tutoriels en ligne suivants, sur le site de DataCamp. Pour chacun des tutoriels, j’indique une liste des concepts de programmation couverts. Notez que dans ce livre, nous utiliserons une police différente pour distinguer le texte normal et les commandes-informatiques. Il est important de noter que, bien que ces tutoriels sont d’excellentes introductions, une seule lecture est insuffisante pour un apprentissage en profondeur et une rétention à long terme. Les outils ultimes pour l’apprentissage et la rétention à long terme sont “l’apprentissage par la pratique” et “la répétition”. Outre les exercices demandés dans DataCamp, que vous devez effectuer directement dans votre navigateur, je vous encourage donc à multiplier les essais, directement dans la console de RStudio, ou, de préférence, dans un script que vous annoterez, pour vous assurer que vous avez bien compris chaque partie. 2.2.4.1 Objets, types, vecteurs, facteurs et tableaux de données Dans le cours d’introduction à R sur DataCamp, suivez les chapitres suivants. Au fur et à mesure de votre travail, notez les termes importants et ce à quoi ils font référence. Chapitre 1 : introduction La console : l’endroit où vous tapez des commandes Les objets : où les valeurs sont stockées, comment assigner des valeurs à des objets Les types de données : entiers, doubles/numériques, charactères et logiques Chapitre 2 : vecteurs Les vecteurs : des collections de valeurs du même type. Chapitre 4 : les facteurs Des données catégorielles (et non pas numériques) représentés dans R sous forme de factors. Chapitre 5 : les jeux de données ou data.frame Les data.frames sont similaires aux feuilles de calcul rectangulaires que l’on peut produire dans un tableur. Dans R, ce sont des objets rectangulaires (des tableaux !) contenant des jeux de jeux de données : les lignes correspondent aux observations et les colonnes aux variables décrivant les observations. La plupart du temps, c’es le format de données que nous utiliserons. Plus de détails dans la partie 3. Avant de passer à la suite, il nous reste 2 grandes notions à découvrir dans le domaine du code et de la syntaxe afin de pouvoir travailler efficacement dans R : les opérateurs de comparaison d’une part, et les fonctions d’autre part. 2.2.4.2 Opérateurs de comparaison Comme leur nom l’indique, ils permettent de comparer des valeurs ou des objets. Les principaux opérateurs de comparaison sont : == : égale à != : différent de &gt; : supérieur à &lt; : inférieur à &gt;= : supérieur ou égal à &lt;= : inférieur ou égal à Ainsi, on peut tester si 3 est égal à 5 : 3 == 5 [1] FALSE La réponse est bien entendu FALSE. Est-ce que 3 est inférieur à 5 ? 3 &lt; 5 [1] TRUE La réponse est maintenant TRUE. Lorsque l’on utilise un opérateur de comparaison, la réponse est toujours soit vrai (TRUE), soit faux (FALSE). Il est aussi possible de comparer des chaînes de charactères : &quot;Bonjour&quot; == &quot;Au revoir&quot; [1] FALSE &quot;Bonjour&quot; &gt;= &quot;Au revoir&quot; [1] TRUE Manifestement, “Bonjour” est supérieur ou égal à “Au revoir”. En fait, R utilise l’ordre alphabétique pour comparer les chaînes de caractères. Puisque dans l’alphabet, le “B” de “Bonjour” arrive après le “A” de “Au revoir”, pour R, “Bonjour” est bien supérieur à “Au revoir”. Il est également possible d’utiliser ces opérateurs pour comparer un chiffre et un vecteur : tailles_pop1 &lt;- c(112, 28, 86, 14, 154, 73, 63, 48) tailles_pop1 &gt; 80 [1] TRUE FALSE TRUE FALSE TRUE FALSE FALSE FALSE Ici, l’opérateur nous permet d’identifier quels éléments du vecteur taille_pop1 sont supérieurs à 80. Il s’agit des éléments placés en première, troisième et cinquième position. Il est aussi possible de comparer 2 vecteurs qui contiennent le même nombre d’éléments : tailles_pop2 &lt;- c(114, 27, 38, 91, 54, 83, 33, 68) tailles_pop1 &gt; tailles_pop2 [1] FALSE TRUE TRUE FALSE TRUE FALSE TRUE FALSE Les comparaisons sont ici faites élément par élément. Ainsi, les observations 2, 3, 5 et 7 du vecteur tailles_pop1 sont supérieures aux observations 2, 3, 5 et 7 du vecteur tailles_pop2 respectivement. Ces vecteurs de vrais/faux sont très utiles car ils peuvent permettre de compter le nombre d’éléments répondant à une certains condition : sum(tailles_pop1 &gt; tailles_pop2) [1] 4 Lorsque l’on effectue une opération arithmétique (comme le calcul d’une somme ou d’une moyenne) sur un vecteur de vrais/faux, les TRUE sont remplacés par 1 et les FALSE par 0. La somme nous indique donc le nombre de vrais dans un vecteur de vrais/faux, et la moyenne nous indique la proportion de vrais : mean(tailles_pop1 &gt; tailles_pop2) [1] 0.5 Note : Attention, si les vecteurs comparés n’ont pas la même taille, un message d’avertissement est affiché : tailles_pop3 &lt;- c(43, 56, 92) tailles_pop1 [1] 112 28 86 14 154 73 63 48 tailles_pop3 [1] 43 56 92 tailles_pop3 &gt; tailles_pop1 Warning in tailles_pop3 &gt; tailles_pop1: la taille d&#39;un objet plus long n&#39;est pas multiple de la taille d&#39;un objet plus court [1] FALSE TRUE TRUE TRUE FALSE TRUE FALSE TRUE Dans un cas comme celui là, R va recycler l’objet le plus court, ici tailles_pop3 pour qu’une comparaison puisse être faite avec chaque élément de l’objet le plus long (ici, tailles_pop1). Ainsi, 43 est comparé à 112, 56 est comparé à 28 et 92 est comparé à 86. Puisque tailles_pop3 ne contient plus d’éléments, ils sont recyclés, dans le même ordre : 43 est comparé à 14, 56 est comparé à 154, et ainsi de suite jusqu’à ce que tous les éléments de tailles_pop1 aient été passés en revue. Ce type de recyclage est très risqué car il est difficile de savoir ce qui a été comparé avec quoi. En travaillant avec des tableaux plutôt qu’avec des vecteurs, le problème est généralement évité puisque toutes les colonnes d’un data.frame contiennent le même nombre d’éléments. Dernière chose concernant les opérateurs de comparaison : la question des données manquantes. Dans R les données manquantes sont symbolisées par cette notation : NA, abréviation de “Not Available”. Le symbole NaN est parfois aussi observé lorsque des opérations ont conduit à des indéterminations. Mais c’est plus rare et la plupart du temps, les NaNs peuvent être traités comme les NAs. L’un des problèmes des données manquantes, est qu’il est nécessaire de prendre des précautions pour réaliser des comparaison les impliquants : 3 == NA [1] NA On s’attend logiquement à ce que 3 ne soit pas considéré comme égal à NA, et donc, on s’attend à obtenir FALSE. Pourtant, le résultat est NA. La comparaison d’un élément quelconque à une donnée manquante fournit toujours une donnée manquante : la comparaison ne peut pas se faire, R n’a donc rien à retourner. C’est également le cas aussi lorsque l’on compare deux valeurs manquantes : NA == NA [1] NA C’est pourtant assez logique. Imaginons que j’ignore l’âge de Pierre et l’âge de Marie. Il n’y a aucune raison pour que leur âge soit le même, mais il est tout à fait possible qu’il le soit. C’est impossible à déterminer : age_Pierre &lt;- NA age_Marie &lt;- NA age_Pierre == age_Marie [1] NA Mais alors comment faire pour savoir si une valeur est manquante puisqu’on ne peut pas utiliser les opérateurs de comparaison ? On utilise la fonction is.na() : is.na(age_Pierre) [1] TRUE is.na(tailles_pop3) [1] FALSE FALSE FALSE D’une façon générale, le point d’exclamation permet de signifier à R que nous souhaitons obtenir le contraire d’une expression : !is.na(age_Pierre) [1] FALSE !is.na(tailles_pop3) [1] TRUE TRUE TRUE Cette fonction nous sera très utile plus tard pour éliminer toutes les lignes d’un tableau contenant des valeurs manquantes. 2.2.4.3 L’utilisation des fonctions Dans R, les fonctions sont des objets particuliers qui permettent d’effectuer des tâches très variées. Du calcul d’une moyenne à la création d’un graphique, en passant par la réalisation d’analyses statistiques complexes ou simplement l’affichage du chemin du répertoire de travail, tout, dans R, repose sur l’utilisation de fonctions. Vous en avez déjà vu un certain nombre : Fonction Pour quoi faire ? c() Créer des vecteurs class() Afficher ou modifier la classe d’un objet factor() Créer des facteurs getwd() Afficher le chemin du répertoire de travail head() Afficher les premiers éléments d’un objet is.na() Tester si un objet contient des valeurs manquantes mean() Calculer une moyenne names() Afficher ou modifier le nom des éléments d’un vecteur order() Ordonner les éléments d’un objet setwd() Modifier le chemin du répertoire de travail subset() Extraire une partie des éléments d’un objet sum() Calculer une somme tail() Afficher les derniers éléments d’un objet Cette liste va très rapidement s’allonger au fil des séances. Je vous conseille donc vivement de tenir à jour une liste des fonctions décrites, avec une explication de leur fonctionnement et éventuellement un exemple de syntaxe. Certaines fonction ont besoin d’arguments (par exemple, la fonction factor()), d’autres peuvent s’en passer (par exemple, la fonction getwd()). Pour apprendre comment utiliser une fonction particulière, pour découvrir quels sont ses arguments possibles, quelle est leur rôle et leur intérêt, la meilleure solution est de consulter l’aide de cette fonction. Il suffit pour cela de taper un ? suivi du nom de la fonction : ?factor() Toutes les fonctions et jeux de données disponibles dans R disposent d’un fichier d’aide similaire. Cela peut faire un peu peur au premier abord (tout est en anglais !), mais ces fichiers d’aide ont l’avantage d’être très complets, de fournir des exemples d’utilisation, et ils sont tous construits sur le même modèle. Vous avez donc tout intérêt à vous familiariser avec eux. vous devriez d’ailleurs prendre l’habitude de consulter l’aide de chaque fonction qui vous pose un problème. Par exemple, le logarithme (en base 10) de 100 devrait faire 2, car 100 est égal à 10^2. Pourtant : log(100) [1] 4.60517 Que se passe-t’il ? Pour le savoir, il faut consulter l’aide de la fonction log : ?log() Ce fichier d’aide nous apprend que par défaut, la syntaxe de la fonction log() est la suivante : log(x, base = exp(1)) Par défaut, la base du logarithme est fixée à exp(1). Nous avons donc calculé un logarithme népérien (en base e). Cette fonction prend donc 2 arguments : 1. x ne possède pas de valeur par défaut : il nous faut obligatoirement fournir quelque chose (la rubrique “Argument” du fichier d’aide nous indique que x doit être un vecteur numérique ou complexe) afin que la fonction puisse calculer un logarithme 2. base possède un argument par défaut. Si nous ne spécifions pas nous même la valeur de base, elle sera fixée à sa valeur par défaut, c’est à dire exp(1). Pour calculer le logarithme en base 10 de 100, il faut donc taper, au choix, l’une de ces 3 expressions : log(x = 100, base = 10) [1] 2 log(100, base = 10) [1] 2 log(100, 10) [1] 2 Le nom des arguments d’une fonction peut être omis tant que ces arguments sont indiqués dans l’ordre attendu par la fonction (cet ordre est celui qui est précisé à la rubrique “Usage” du fichier d’aide de la fonction). Il est possible de modifier l’ordre des arguments d’une fonction, mais il faut alors être parfaitement explicite et utiliser les noms des arguments tels que définis dans le fichier d’aide. Ainsi, pour calculer le logarithme en base 10 de 100, on ne peut pas taper : log(10, 100) [1] 0.5 car cela revient à calculer le logarithme en base 100 de 10. On peut en revanche taper : log(base = 10, x = 100) [1] 2 2.3 Les packages additionels Une source de confusion importante pour les nouveaux utilisateurs de R est la notion de package. Les packages étendent les fonctionnalités de R en fournissant des fonctions, des données et de la documentation supplémentaires et peuvent être téléchargés gratuitement sur Internet. Ils sont écrits par une communauté mondiale d’utilisateurs R. Par exemple, parmi plus de 13000 packages disponibles à l’heure actuelle, nous utiliseront fréquemment : Le package ggplot2 pour la visualisation des données dans le chapitre 4 Le package dplyr pour les manipuler des tableaux données dans le chapitre 6 Il y a deux choses importantes à retenir à propos des packages R : Installation : la plupart des packages ne sont pas installés par défaut lorsque vous installez R et RStudio. Vous devez installer un package avant de pouvoir l’utiliser. Une fois que vous l’avez installé, vous n’avez probablement pas besoin de l’installer à nouveau, sauf si vous souhaitez le mettre à jour vers une version plus récente du package. Chargement : les packages ne sont pas chargés automatiquement lorsque vous ouvrez RStudio. Vous devez les charger chaque fois que vous ouvrez RStudio en utilisant la commande library (). Une bonne analogie pour les packages R : ils sont comme les apps que vous téléchargez sur un téléphone portable : R : Un nouveau téléphone Packages: Apps qu’on peut telécharger R est comme un nouveau téléphone mobile. Il est capable de faire certaines choses lorsque vous l’utilisez pour la première fois, mais il ne sait pas tout faire. Les packages R sont comme les apps que vous pouvez télécharger dans l’App Store et Google Play. Pour utiliser un package, comme pour utiliser Instagram, vous devez : 1. Le télécharger et l’installer. Vous ne le faites qu’une fois. 1. Le charger (en d’autres termes, l’ouvrir) en utilisant la commande library (). Donc, tout comme vous ne pouvez commencer à partager des photos avec vos amis sur Instagram que si vous installez d’abord l’application et que vous l’ouvrez, vous ne pouvez accéder aux données et fonctions d’un package R que si vous installez d’abord le package et le chargez avec la fonction library(). Passons en revue ces 2 étapes. 2.3.1 Installation d’un package Il y a deux façons d’installer un package. Par example, pour installer le package ggplot2 : Le plus simple : Dans le panneau “File” de Rstudio : Cliquez sur l’onglet “Packages” Cliquez sur “Install” Tapez le nom du package dans le champ “Packages (separate multiple with space or comma):” Pour notre exemple, tapez ggplot2 Cliquez “Install” Métode alternative : Dans la console, tapez install.packages(&quot;ggplot2&quot;) (vous devez inclure les guillemets). En procédant de l’une ou l’autre façon, installez également les packages suivants : tidyverse et nycflights13. Note : un package doit être installé une fois seulement, sauf si une version plus récente est disponible et que vous souhaitez mettre à jour ce package. 2.3.2 Charger un package en mémoire Après avoir installé un package, vous pouvez le charger en utilisant la fonction library(). Par exemple, pour charger ggplot2 et dplyr tapez ceci dans la console : library(ggplot2) library(dplyr) Note : Vous devez charger à nouveau chaque package que vous souhaitez utiliser à chaque fois que vous ouvrez une nouvelle session de travail dans RStudio. Ça peut être un peu pénible et c’est une source d’erreur fréquente pour les débutants. Quand vous vouyez un message d’erreur commençant par : Error: could not find function... rappelez-vous que c’est probablement parce que vous tentez d’utiliser une fonction qui fait partie d’un package que vous n’avez pas chargé. Pour corriger l’erreur, il suffit donc de charger le package approprié avec la commande library(). 2.4 Exercices Créez un nouveau script que vous nommerez VotreNomDeFamille.R. Vous prendrez soin d’ajouter autant de commentaires que nécessaire dans votre script afin de le structurer correctement. Téléchargez (si besoin) et chagez le package ggplot2 Chargez le jeu de données diamonds grâce à la commande data(diamonds) Déterminer le nombre de lignes et de colonnes de ce tableau nommé diamonds Créez un nouveau tableau que vous nommerez diamants_chers qui contiendra uniquement les informations des diamants dont le prix est supérieur ou égal à $15000 Combien de diamants coûtent $15000 ou plus ? Cela représente quelle proportion du jeu de données de départ ? Triez ce tableau par ordre de prix décroissant et affichez les informations des 20 diamants les plus chers. Déposez votre script sur l’ENT au moins une heure avant votre prochaine séance de travaux pratiques. "],
["dataset.html", "3 Explorez votre premier jeu de données 3.1 Le package nycflights13 3.2 Le data frame flights 3.3 Explorer un data.frame 3.4 Exercices", " 3 Explorez votre premier jeu de données Mettons en pratique tout ce que nous avons appris pour commencer à explorer un jeu de données réelles. Les données nous parviennent sous différents formats, des images au texte en passant par les chiffres. Tout au long de ce document, nous nous concentrerons sur les ensembles de données qui peuvent être stockés dans une feuille de calcul, car il s’agit de la manière la plus courante de collecter des données dans de nombreux domaines. N’oubliez pas ce que nous avons appris dans la section 2.2.4.1 : ces ensembles de données de type “tableurs” sont appelés data.frame dans R, et nous nous concentrerons sur l’utilisation de ces objets tout au long de ce livre. Commençons par charger les packages nécessaires pour ce chapitre (cela suppose que vous les ayez déjà installés. Relisez la Section 2.3 pour plus d’informations sur l’installation et le chargement des packages R si vous ne l’avez pas déjà fait). Au début de chaque chapitre, nous aurons systématiquement besoin de charger quelques packages. Donc n’oubliez pas de les installer au préalable si besoin. # Pensez à installer ces packages avant de les charger si besoin library(dplyr) library(nycflights13) 3.1 Le package nycflights13 Nous avons probablement déjà presque tous pris l’avion. Les grands aéroports contiennent de nombreuses portes d’embarquement, et pour chacune d’elles, des informations sur les vols en partance sont affichées. Par exemple, le numéro du vol, les heures de décollage et d’aterrissage prévues, les retards etc. Dans la mesure du possible, on aime arriver à destination à l’heure. Dans la suite de ce document, on examinera ce jeu de données, notamment afin d’en apprendre plus sur les causes de retard les plus fréquentes. Ce package contient 5 “tableaux” contenant des informations sur chaque vol intérieur qui ayant quitté New York en 2013, soit depuis l’aéroport de Newark Liberty International (EWR), soit depuis l’aéroport Jonh F. Kennedy Intenational (JFK), soit depuis l’aéroport LaGuardia (LGA) : flights : informations sur chacun des 336776 vols airlines : traduction entre les codes IATA à 2 lettres des compagnies aériennes et leur nom complet (il y en a 16 au total) planes : informations constructeurs pour chacun des 3322 avions utilisés en 2013 weather : données météorologiques heure par heure (environ 8705 observations) pour chacun des 3 aéroports de New York airports : noms et localisation géographiques des aéroports desservis (1458 aéroports) 3.2 Le data frame flights Nous allons commencer par explorer le jeu de données flights qui est inclus avec le package nycflights13 afin de nous faire une idée de sa structure. Dans votre script, tapez la commande suivante et exécutez là dans la console (selon les réglages de RStudio et la largeur de votre console, l’affichage peut varier légèrement) : flights # A tibble: 336,776 x 19 year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; 1 2013 1 1 517 515 2 830 819 2 2013 1 1 533 529 4 850 830 3 2013 1 1 542 540 2 923 850 4 2013 1 1 544 545 -1 1004 1022 5 2013 1 1 554 600 -6 812 837 6 2013 1 1 554 558 -4 740 728 7 2013 1 1 555 600 -5 913 854 8 2013 1 1 557 600 -3 709 723 9 2013 1 1 557 600 -3 838 846 10 2013 1 1 558 600 -2 753 745 # ... with 336,766 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; Essayons de décrypter cet affichage : A tibble: 336,776 x 19 : un tibble est un data.frame amélioré. Il a toutes les caractéristiques d’un data.frame, (tapez class(flights) pour vous en convaincre), mais en plus, il a quelques propriétés intéressantes sur lesquelles nous reviendrons plus tard. Ce tibble possède donc : 336776 lignes 19 colonnes, qui correspondent aux variables Dans un tibble, les observations sont toujours en ligne et les variables en colonnes. year, month, day, dep_time, sched_dep_time… Sont les noms des colonnes, c’est à dire les variables de ce jeu de données. Nous avons ensuite les 10 premières lignes du tableau qui correspondent à 10 vols. ... with 336,766 rows, and 11 more variables : nous indique que 336766 lignes et 11 variables ne logent pas à l’écran. Ces données font toutefois partie intégrante du tableau flights. le nom et le type de chaque variable qui n’a pas pu être affichée à l’écran Cette façon d’afficher les tableaux est spécifique des tibbles. Vous noterez que le type de chaque variable est indiqué entre &lt;...&gt;. Les types que vous pourrez rencontrer sont les suivants : &lt;int&gt; : nombres entiers (“integers”) &lt;dbl&gt; : nombres réels (“doubles”) &lt;chr&gt; : charactères &lt;fct&gt; : facteurs &lt;ord&gt; : facteurs ordonnés &lt;lgl&gt; : logiques (colonne de vrais/faux : “logical”) &lt;date&gt; : dates &lt;time&gt; : heures &lt;dttm&gt; : combinaison de date et d’heure (“date time”) Cette façon d’afficher le contenu d’un tableau permet d’y voir (beaucoup) plus clair que l’affichage classique d’un data.frame. Malheureusement, ce n’est pas toujours suffisant. Voyons quelles sont les autres méthodes permettant d’explorer un data.frame. 3.3 Explorer un data.frame Parmi les nombreuses façons d’avoir une idée des données contenues dans un data.frame tel que flights, on présente ici 2 fonctions qui prennent le nom du data.frame en guise d’argument et un opérateur : la fonction View() intégrée à RStudio. C’est celle que vous utiliserez le plus souvent. Attention, elle s’écrit avec un “V” majuscule. la fonction glimpse() chargée avec le package dplyr. Elle est très similaire à la fonction str() découverte dans les tutoriels de DataCamp. l’opérateur $ permet d’accéder à une unique variable d’un data.frame. 3.3.1 View() Tapez View(flights) dans votre script et exécutez la commande. Un nouvel onglet contenant ce qui ressemble à un tableaur doit s’ouvrir. Question : à quoi correspond chacune des lignes de ce tableau ? A. aux données d’une compagnie aérienne B. aux données d’un vol C. aux données d’un aéroport D. aux données de plusieurs vols Ici, vous pouvez donc explorer la totalité du tableau, passer chaque variable en revue, et même appliquer des filtres pour ne visualiser qu’une partie des données. Par exemple, essayez de déterminer combien de vols ont décollé de l’aéroport JFK le 12 février. Ce tableau n’est pas facile à manipuler. Il est impossible de corriger des valeurs, et lorsque l’on applique des filtres, il est impossible de récuppérer uniquement les données filtrées. Nous verrons plus tard comment les obtenir en tapant des commandes simples dans un script. La seule utilité de ce tableau est donc l’exploration visuelle des données. 3.3.2 glimpse() La seconde façon d’explorer les données contenues dans un tableau est d’utiliser la fonction glimpse() après avoir chargé le package dplyr : glimpse(flights) Observations: 336,776 Variables: 19 $ year &lt;int&gt; 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013... $ month &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1... $ day &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1... $ dep_time &lt;int&gt; 517, 533, 542, 544, 554, 554, 555, 557, 557, 558, 55... $ sched_dep_time &lt;int&gt; 515, 529, 540, 545, 600, 558, 600, 600, 600, 600, 60... $ dep_delay &lt;dbl&gt; 2, 4, 2, -1, -6, -4, -5, -3, -3, -2, -2, -2, -2, -2,... $ arr_time &lt;int&gt; 830, 850, 923, 1004, 812, 740, 913, 709, 838, 753, 8... $ sched_arr_time &lt;int&gt; 819, 830, 850, 1022, 837, 728, 854, 723, 846, 745, 8... $ arr_delay &lt;dbl&gt; 11, 20, 33, -18, -25, 12, 19, -14, -8, 8, -2, -3, 7,... $ carrier &lt;chr&gt; &quot;UA&quot;, &quot;UA&quot;, &quot;AA&quot;, &quot;B6&quot;, &quot;DL&quot;, &quot;UA&quot;, &quot;B6&quot;, &quot;EV&quot;, &quot;B6&quot;... $ flight &lt;int&gt; 1545, 1714, 1141, 725, 461, 1696, 507, 5708, 79, 301... $ tailnum &lt;chr&gt; &quot;N14228&quot;, &quot;N24211&quot;, &quot;N619AA&quot;, &quot;N804JB&quot;, &quot;N668DN&quot;, &quot;N... $ origin &lt;chr&gt; &quot;EWR&quot;, &quot;LGA&quot;, &quot;JFK&quot;, &quot;JFK&quot;, &quot;LGA&quot;, &quot;EWR&quot;, &quot;EWR&quot;, &quot;LG... $ dest &lt;chr&gt; &quot;IAH&quot;, &quot;IAH&quot;, &quot;MIA&quot;, &quot;BQN&quot;, &quot;ATL&quot;, &quot;ORD&quot;, &quot;FLL&quot;, &quot;IA... $ air_time &lt;dbl&gt; 227, 227, 160, 183, 116, 150, 158, 53, 140, 138, 149... $ distance &lt;dbl&gt; 1400, 1416, 1089, 1576, 762, 719, 1065, 229, 944, 73... $ hour &lt;dbl&gt; 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6... $ minute &lt;dbl&gt; 15, 29, 40, 45, 0, 58, 0, 0, 0, 0, 0, 0, 0, 0, 0, 59... $ time_hour &lt;dttm&gt; 2013-01-01 05:00:00, 2013-01-01 05:00:00, 2013-01-0... Ici, les premières observations sont présentées en lignes pour chaque variable du jeu de données. Là encore, le type de chaque variable est précisé. Essayez d’identifier 3 variables catégorielles. À quoi correspondent-elles ? En quoi sont-elles différentes des variables numériques ? 3.3.3 L’opérateur $ Enfin, l’opérateur $ permet d’accéder à une unique variable grâce à son nom. Par exemple le tableau airlines contient seulement 2 variables : airlines # A tibble: 16 x 2 carrier name &lt;chr&gt; &lt;chr&gt; 1 9E Endeavor Air Inc. 2 AA American Airlines Inc. 3 AS Alaska Airlines Inc. 4 B6 JetBlue Airways 5 DL Delta Air Lines Inc. 6 EV ExpressJet Airlines Inc. 7 F9 Frontier Airlines Inc. 8 FL AirTran Airways Corporation 9 HA Hawaiian Airlines Inc. 10 MQ Envoy Air 11 OO SkyWest Airlines Inc. 12 UA United Air Lines Inc. 13 US US Airways Inc. 14 VX Virgin America 15 WN Southwest Airlines Co. 16 YV Mesa Airlines Inc. Nous pouvons accéder à ces variables grâce à leur nom : airlines$name [1] &quot;Endeavor Air Inc.&quot; &quot;American Airlines Inc.&quot; [3] &quot;Alaska Airlines Inc.&quot; &quot;JetBlue Airways&quot; [5] &quot;Delta Air Lines Inc.&quot; &quot;ExpressJet Airlines Inc.&quot; [7] &quot;Frontier Airlines Inc.&quot; &quot;AirTran Airways Corporation&quot; [9] &quot;Hawaiian Airlines Inc.&quot; &quot;Envoy Air&quot; [11] &quot;SkyWest Airlines Inc.&quot; &quot;United Air Lines Inc.&quot; [13] &quot;US Airways Inc.&quot; &quot;Virgin America&quot; [15] &quot;Southwest Airlines Co.&quot; &quot;Mesa Airlines Inc.&quot; Cela nous permet de récupérer les données sous la forme d’un vecteur. Attention toutefois, le tableau flights contient tellement de lignes, que récuppérer une variable grâce à cet opérateur peut rapidement saturer la console. Si, par exemple, vous souhaitez extraire les données relatives aux compagnies aériennes (colonne carrier) du tableau flights, vous pouvez taper ceci : flights$carrier Le résultat est pour le moins indigeste ! Lorsqu’un tableau contient de nombreuses lignes, c’est rarement une bonne idée de transformer l’une de ses colonnes en vecteur. Dans la mesure du possible, les données d’un tableau doivent rester dans le tableau. 3.3.4 Les fichiers d’aide Une fonctionalité particulièrement utile de R est son système d’aide. On peut obtenir de l’aide au sujet de n’importe quelle fonction et de n’importe quel jeu de données en tapan un ? immédiatement suivi du nom de la fonction ou de l’objet. Par exemple, examinez l’aide du jeu de données flights : ?flights Vous devriez absolument prendre l’habitude d’examiner les fichiers d’aide des fonctions ou jeux de données pour lesquels vous avez des questions. Ces fichiers sont très complets, et même s’il peuvent paraître impressionants au premier abord, ils sont tous structurés sur le même modèle et vous aideront à comprendre comment utiliser les fonctions, quels sont les arguments possibles, à quoi ils servent et comment les utiliser. Prenez le temps d’examiner le fichier d’aide du jeu de données flights. Avant de passer à la suite, assurez-vous d’avoir compris à quoi correspondent chacune des 19 variables de ce tableau. 3.4 Exercices Consultez l’aide du jeu de données diamonds du package ggplot2. Quel est le code de la couleur la plus prisée ? Quel est le code de la moins bonne clarté ? À quoi correspond la variable z ? En quoi la variable depth est-elle différente de la variable z ? Consultez l’aide du package nycflights13 en tapant help(package=&quot;nycflights13&quot;). Consultez l’aide des 5 jeux de données de ce package. À quoi correspond la variable visib ? Dans quel tableau se trouve-t’elle ? Combien de lignes possède ce tableau ? "],
["viz.html", "4 Visualiser des données avec ggplot2 4.1 Prérequis 4.2 La grammaire des graphiques 4.3 Les nuages de points 4.4 Les graphiques en lignes 4.5 Les histogrammes 4.6 Les facets 4.7 Les boîtes à moustaches ou boxplots 4.8 Les diagrammes bâtons", " 4 Visualiser des données avec ggplot2 Dans les chapitres 2 et 3, nous avons vu ce qui me semble être les concepts essentiels avant de commencer à explorer en détail des données dans R. Les éléments de syntaxe abordés dans la section 2.2 sont nombreux et vous n’avez probablement pas tout retenu. C’est pourquoi je vous conseille de garder les tutoriels de DataCamp à portée de main afin de pouvoir refaire les parties que vous maîtrisez le moins. Ce n’est qu’en répétant plusieurs fois ces tutoriels que les choses seront vraiment comprises et que vous les retiendrez. Ainsi, si des éléments de code présentés ci-dessous vous semblent obscures, revenez en arrière : toutes les réponses à vos questions se trouvent probablement dans les chapitres précédents. Après la découverte des bases du langage R, nous abordons maintenant les parties de ce livre qui concernent la “science des données” (ou “Data Science” pour nos amis anglo-saxons). Nous allons voir dans ce chapitre qu’outre les fonctions View() et glimpse(), l’exploration visuelle via la représentation graphique des données est un moyen indispensable et très puissant pour comprendre ce qui se passe dans un jeu de données. La visualisation de vos données devrait toujours être un préambule à toute analyse statistique. La visualisation des données est en outre un excellent point de départ quand on découvre la programmation sous R, car ses bénéfices sont clairs et immédiats : vous pouvez créer des graphiques élégants et informatifs qui vous aident à comprendre les données. Dans ce chapitre, vous allez donc plonger dans l’art de la visualisation de données, en apprenant la structure de base des graphiques réalisés avec ggplot2 qui permettent de transformer des données numériques et catégorielles en graphiques. Toutefois, la visualisation seule ne suffit généralement pas. Il est en effet souvent nécessaire de transformer les données pour produire des représentations plus parlantes. Ainsi, dans les chapitres 5 et 6, vous découvrirez les verbes clés qui vous permettront de sélectionner des variables importantes, de filtrer les observations clés, de créer de nouvelles variables, de calculer des résumés, d’associer des tableaus ou de les remettre en forme. C’est en combinant la transformation des données et les représentations graphiques avec votre curiosité et votre esprit critique, vous serez véritablement en mesure de réaliser l’analyse exploratoire de données, seul procédé permettant de poser des questions intéressantes et pertinentes sur les données et afin d’y répondre. 4.1 Prérequis Dans ce chapitre, nous aurons besoin des packages suivants : library(ggplot2) library(nycflights13) library(dplyr) Si ce n’est pas déjà fait pensez à les installer avant de les charger en mémoire. Au niveau le plus élémentaire, les graphiques permettent de comprendre comment les variables se comparent en termes de tendance centrale (à quel endroit les valeurs ont tendance à être localisées, regroupées) et leur dispersion (comment les données varient autour du centre). La chose la plus importante à savoir sur les graphiques est qu’ils doivent être créés pour que votre public (le prof qui vous évalue, le collègue avec qui vous collaborez, votre futur patron, etc.) comprenne bien les résultats et les informations que vous souhaitez transmettre. Il s’agit d’un exercice d’équilibriste : d’une part, vous voulez mettre en évidence autant de relations significatives et de résultats intéressants que possible, mais de l’autre, vous ne voulez pas en inclure trop, afin d’éviter de rendre votre graphique illisible ou de submerger votre public. Tout comme n’importe quel paragraphe de document écrit, un graphique doit permettre de communiquer un message (une idée forte, un résultat marquant, une hypothèse nouvelle, etc). Comme nous le verrons, les graphiques nous aident également à repérer les tendances extrêmes et les valeurs aberrantes dans nos données. Nous verrons qu’une façon de faire assez classique consiste à comparer la distribution d’une variable quantitative pour les différents niveaux d’une variable catégorielle. 4.2 La grammaire des graphiques Les lettres gg du package ggplot sont l’abbréviation de “grammar of graphics” : la grammaire des graphiques. De la même manière que nous construisons des phrases en respectant des règles grammaticales précises (usage des noms, des verbes, des sujets et adjectifs…), la grammaire des graphiques établit un certain nombre de règles permettant de construire des graphiques : elle précise les composants d’un graphique en suivant le cadre théorique défini par Wilkinson (2005). 4.2.1 Éléments de la grammaire En bref, la grammaire des graphiques nous dit que : Un graphique est l’association (mapping) de données/variables (data) à des attributs esthétiques (aesthetics) d’objets géométriques (geometric objects). Pour clarifier, on peut disséquer un graphique en 3 éléments esentiels : data : le jeu de données contenant les variables que l’on va associer à des objets géométriques geom : les objets géométriques en question. Cela fait référence aux types d’objets que l’on peut observer sur le graphiques (des points, des lignes, des barres, etc) aes : les attributs esthétiques des objets géométriques présents sur le graphique. Par exemple, la position sur les axes x et y, la couleur, la taille, la transparence, la forme, etc. Chacun de ces attributs esthétiques peut-être associé à une variable de notre jeu de données. Examinons un exemple pour bien comprendre. 4.2.2 Gapminder En février 2006, un statisticien du nom de Hans Rosling a donné un TED Talk intitulé “The best stats you’we ever seen”. Au cours de cette conférence, Hans Rosling présente des données sur l’économie mondiale, la santé et le développement des pays du monde. Les données sont disponibles sur ce site et dans le package gapminder. Pour l’année 2007, le jeu de données contient des informations pour 142 pays. Examinons les premières lignes de ce jeu de données : Table 4.1: Les 6 premières lignes du jeu de données gapminder pour l’année 2007 Country Continent Life Expectancy Population GDP per Capita Afghanistan Asia 43.828 31889923 974.5803 Albania Europe 76.423 3600523 5937.0295 Algeria Africa 72.301 33333216 6223.3675 Angola Africa 42.731 12420476 4797.2313 Argentina Americas 75.320 40301927 12779.3796 Australia Oceania 81.235 20434176 34435.3674 Pour chaque ligne, les variables suivantes sont décrites : Country : le pays Continent : le continent Life Expectancy : espérance de vie à la naissance Population : nombre de personnes vivant dans le pays GDP per Capita : produit intérieur brut (PIB) par habitant en dollars américains. GDP est l’abréviation de “Growth Domestic Product”. C’est un indicateur de l’activité économique d’un pays, parfois utilisé comme une approximation du revenu moyen par habitant. Examinons maintenant la figure 4.1 qui représente ces variables pour chacun des 142 pays de ce jeu de données (notez l’utilisation de la notation scientifique dans la légende). Figure 4.1: Espérance de vie en fonction du PIB par habitant en 2007 Si on décrypte ce graphique du point de vue de la grammaire des graphiques, on voit que : la variable GDP per Capita est associée à l’aesthetic x de la position des points la variable Life Expectancy est associée à l’aesthetic y de la position des points la variable Population est associée à l’aesthetic size (taille) des points la variable Continent est associée à l’aesthetic color (couleur) des points Ici, l’objet géométrique (ou geom) qui représente les données est le point. Les données (ou data) sont contenues dans le tableau gapminder et chaune de ces variables est associée (mapping) aux caractéristiques esthétiques des points. 4.2.3 Autres éléments de la grammaire des graphiques Outre les éléments indispensables évoqués ici (data, mapping, aes, et geom), il existe d’autres aspects de la grammaire des graphiques qui permettent de contrôler l’aspect des graphiques. Ils ne sont pas toujours indispensables. Nous en verrons néanmoins quelque-uns particulièrement utiles : facet : c’est un moyen très pratique de scinder le jeu de données en plusieurs sous-groupe et de produire automatiquement un graphique pour chacun d’entre eux. position : permet notamment de modifier la position des barres d’un barplot. labs : permet de définir les titres, sous-titres et légendes des axes d’un graphique l’ajustement du système de coordonnées. theme : permet de modifier l’apect général des graphiques en appliquant des thèmes prédéfinis ou en modifiant certains aspects de thèmes existants 4.2.4 Le package ggplot2 Comme indiqué plus haut, le package ggplot2 (Wickham et al. 2018) permet de réaliser des graphiques dans R en respectant les principes de la grammaire des graphiques. Vous avez probablement remarqué que depuis le début de la section 4.2, beaucoup de termes sont écrits dans la police réservée au code informatique. C’est parce que les éléments de la grammaire des graphiques sont tous précisés dans la fonction ggplot() qui demande, au grand minimum, que les éléments suivants soient spécifiés : le nom du data.frame contenant les variables qui seront utilisées pour le graphique. Ce nom correspond à l’argument data de la fonction ggplot(). l’association des variables à des attributs esthétiques. Cela se fait grâce à l’argument mapping et la fonction aes() Après avoir spécifié ces éléments, on ajoute des couches supplémentaires au graphique grâce au signe +. La couche la plus essentielle à ajouter à un graphique, est une couche contenant un élément géométrique, ou geom (par exemple des points, des lignes ou des barres). D’autres couches peuvent s’ajouter pour spécifier des titres, des facets ou des modifications des axes et des thèmes du graphique. Dans le cadre de ce cours, nous nous limiterons aux 5 types de graphiques suivants : les nuages de points les graphiques en lignes les boîtes à moustaches ou boxplots les histogrammes les diagrammes bâtons 4.3 Les nuages de points C’est probablement le plus simple des 5 types de graphiques citées plus haut. Il s’agit de graphiques bi-variés pour lesquels une variable est associée à l’axe des abscisses, et une autre est associée à l’axe des ordonnées. Comme pour le graphique présenté à la figure @ref(fig:gapminder_fig) ci-dessus, d’autres variables peuvent être associées à des caractéristiques esthétiques des points (transparence, taille, couleur, forme…). Nous allons ici nous intéresser à la relation qui existe entre : dep_delay : le retard des vols au décollage, que nous placerons sur l’axe des “x” arr_delay : le retard des mêmes vols à l’aterrissage, que nous placerons sur l’axe des “y” Afin d’avoir un jeu de données plus facile à utiliser, nous nous contenterons de visualiser les vols d’Alaska Airline, donc le code de compagnie aérienne est &quot;AS&quot;. alaska_flights &lt;- flights %&gt;% filter(carrier == &quot;AS&quot;) Il est normal que vous ne compreniez pas encore les commandes ci-dessous. Nous verrons ça plus tard. Retenez juste que nous avons maintenant créer un nouveau tableau, nommé alaska_flights, qui contient toutes les informations des vols d’Alaska Airline. Commencez par examiner ce tableau avec la fonction View(). En quoi est-il différent du tableau flights ? 4.3.1 La couche de base : la fonction ggplot() La fonction ggplot() permet d’établir la première base du graphique. C’est grâce à cette fonction que l’on précise quel jeu de données utiliser et quelle variables placer sur les axes : ggplot(data = alaska_flights, mapping = aes(x = dep_delay, y = arr_delay)) Figure 4.2: Un graphique sans geom Ce graphique est pour le moins vide : c’est normal, nous n’avons pas encore spéifié la couche contenant l’objet géométrique que nous souhaitons utiliser. 4.3.2 Ajout d’une couche supplémentaire : l’objet géométrique Les nuages de points sont créés par la fonction geom_point() : ggplot(data = alaska_flights, mapping = aes(x = dep_delay, y = arr_delay)) + geom_point() Warning: Removed 5 rows containing missing values (geom_point). Figure 4.3: Retards à l’arrivée en fonction des retard au décollage pour les vols d’Alaska Airline au départ de New York City en 2013 plusieurs choses importantes sont à remarquer ici : le graphique présente maintenant une couche supplémentaire constituée de points. la fonction geom_point() nous prévient que 5 lignes contenant des données manquantes n’ont pas été intégrées au graphique. Les données manquent soit pour une variable, soit pour l’autre, soit pour les 2. il est donc impossible de les faire apparaître sur le graphique. il existe une relation positive entre dep_delay et arr_delay : quand le retard d’un vol au décollage augmente, le retard de ce vol augmente aussi à l’arrivée. Enfin, il y a une grande majorité de points centrés près de l’origine (0,0). Si je résume cette syntaxe : Au sein de la fonction ggplot(), on spécifie 2 composants de la grammaire des graphiques : le nom du tableau contenant les données grâce à l’argument data = alaska_flights l’association (mapping) des variables à des caractéristiques esthétiques (aes()) en précisant aes(x = dep_delay, y = arr_delay) : la variable dep_delay est associée à l’esthétique de position x la variable arr_delay est associée à l’esthétique de position y On ajoute une couche au graphique ggplot() grâce au symbole +. La couche en question précise le troisème élément indispensable de la grammaire des graphiques : l’objet geométrique. Ici, les objets sont des points. On le spécifie grâce à la fonction geom_point(). Quelques remarques concernant les couches : Notez que le signe + est placé à la fin de la ligne. Vous recevrez un message d’erreur si vous le placez au début. Quand vous ajoutez une couche à un graphique, je vous encourage vivement à presser la touche enter de votre clavier juste après le symbole +. Ainsi, le code correspondant à chaque couche sera sur une ligne distincte, ce qui augmente considérablement la lisibilité de votre code. Comme indiqué dans la section 2.2.4.3, tant que les arguments d’une fonction sont spécifiés dans l’ordre, on peut se passer d’écrire leur nom. Ainsi, les deux blocs de commande suivants produisent exactement le même résultat : # Le nom des arguments est précisé ggplot(data = alaska_flights, mapping = aes(x = dep_delay, y = arr_delay)) + geom_point() # Le nom des arguments est omis ggplot(alaska_flights, aes(x = dep_delay, y = arr_delay)) + geom_point() 4.3.3 Exercices Donnez une raison pratique expliquant pourquoi les variables dep_delay et arr_delay ont une relation positive Quelles variables (pas nécessairement dans le tableau alaska_flights) pourraient avoir une corrélation négative (relation négative) avec dep_delay ? Pourquoi ? Rappelez-vous que nous étudions ici des variables numériques. Selon vous, pourquoi tant de points sont-il regroupés près de (0, 0) ? À quoi le point (0,0) correspond-il pour les vols d’Alaska Airline ? Citez les éléments de ce graphique/de ces données qui vous sautent le plus aux yeux ? Créez un nouveau nuage de points en utilisant d’autres variables du jeu de données alaska_flights 4.3.4 Over-plotting L’over-plotting est la superposition importante d’une grande quantité d’information sur une zone restreinte d’un graphique. Dans notre cas, nous observons un over-plotting important autour de (0,0). Cet effet est gênant car il est difficile de se faire une idée précise du nombre de points accumulés dans cette zone. La façon la plus simple de régler le problème est de modifier la transparence grâce à l’argument alpha de la fonction geom_point(). Par défaut, cette valeur est fixée à 1, pour une opacité totale. Une valeur de 0 rend les points totalement transparents, et donc invisibles. Trouver la bonne valeur peut demander de tâtonner une peu : ggplot(data = alaska_flights, mapping = aes(x = dep_delay, y = arr_delay)) + geom_point(alpha = 0.2) Figure 4.4: La même figure, avec des points semi-transparents Notez que : la transparence est additive : plus il y a de points, plus la zone est foncée car les points se superposent et rendent la zone plus opaque. l’argument alpha = 0.2 n’est pas intégré à l’intérieur d’une fonction aes() car il n’est pas associé à une variable : c’est un simple paramètre. L’over-plotting est souvent rencontré lorsque l’on représente plusieurs nuages de points pour les différentes valeurs d’une variable catégorielle. par exemple, si on transforme les mois de l’année en facteur (factor(month)), ont peut regarder s’il existe une relation entre les retards à l’aterrissage et le mois de l’année : ggplot(data = alaska_flights, mapping = aes(x = factor(month), y = arr_delay)) + geom_point() Figure 4.5: Retards à l’arrivée pour les 12 mois de l’année 2013 Ici, l’ajout de transparence ne serait pas suffisant. Une autre solution est d’appliquer la mothode dîte de “jittering”, ou tremblement. Elle consiste à ajouter un bruit aléatoire horizontal et/ou vertical aux points d’un graphique. Ici, on peut ajouter un léger bruit horizontal afin de disperser un peu les points pour chaque mois de l’année. On n’ajoute pas de bruit vertical car on ne souhaite pas que les valeurs de retard (sur l’axe des y) soient altérées : ggplot(data = alaska_flights, mapping = aes(x = factor(month), y = arr_delay)) + geom_jitter(width = 0.25) Figure 4.6: Retards à l’arrivée pour les 12 mois de l’année 2013 On y voit déjà plus clair. L’argument width permet de spécifier l’intensité de la dispersion horizontale. Pour ajouter du bruit vertical (ce qui n’est pas souhaitable ici !), on peut ajouter l’argument height. le graphique de la figure 4.6 est parfois appelé un “stripchart”. C’est un graphique du type “nuage de points”, mais pour lequel l’une des 2 variables et numérique, et l’autre est catégorielle. Il est évidemment possible d’ajouter de la transparence : ggplot(data = alaska_flights, mapping = aes(x = factor(month), y = arr_delay)) + geom_jitter(width = 0.25, alpha = 0.5) Figure 4.7: Retards à l’arrivée pour les 12 mois de l’année 2013 4.3.5 Couleur, taille et forme L’argument color (ou colour, les deux orthographes fonctionnent) permet de spécifier la couleur des points. L’argument size permet de spécifier la taille des points. L’argument shape permet de spécifier la forme utilisée en guise de symbole. Ces 3 arguments peuvent être utilisés comme des paramètres, pour modifier l’ensemble des points d’un graphique. Mais ils peuvent aussi être associés à une variable, pour apporter une information supplémentaire. Comparez les deux graphiques suivants : ggplot(data = alaska_flights, mapping = aes(x = dep_delay, y = arr_delay)) + geom_point(color = &quot;blue&quot;) Figure 4.8: Utilisation correcte de color ggplot(data = alaska_flights, mapping = aes(x = dep_delay, y = arr_delay)) + geom_point(aes(color = &quot;blue&quot;)) Figure 4.9: Utilisation incorrecte de color Le code qui permet de produire la figure 4.8 fait un usage correct de l’argument color. On demande des points de couleur bleue, les points apparaîssent bleus. La figure 4.9 en revanche ne produit pas le résultat attendu. Puisque nous avons mis l’argument color à l’intérieur de la fonction aes(), R s’attend à ce que la couleur soit associée à une variable. Puisqu’aucune variable ne s’appelle “blue”, R utilise la couleur par défaut. Pour associer la couleur des points à une variable, nous devons fournir un nom de variable valide : ggplot(data = alaska_flights, mapping = aes(x = dep_delay, y = arr_delay)) + geom_point(aes(color = factor(month))) Figure 4.10: Association de color à une variable catégorielle Ici, l’utilisation de la couleur est correcte. Elle est associée à une variable catégorielle, et chaque valeur possible du vecteur month se voit donc attribuer une couleur différente. ggplot(data = alaska_flights, mapping = aes(x = dep_delay, y = arr_delay)) + geom_point(aes(color = arr_time)) Figure 4.11: Association de color à une variable numérique De la même façon, la couleur des points est ici associée à une variable continue (l’heure d’arrivée des vols). Les points se voient donc attribuer une couleur choisie le long d’un gradient. La même approche peut être utilisée pour spécifier la forme des symboles avec l’argument shape. Attention toutefois : une variable continue ne peut pas être associée à shape ggplot(data = alaska_flights, mapping = aes(x = dep_delay, y = arr_delay)) + geom_point(aes(shape = factor(month))) Figure 4.12: Association de shape à un facteur Vous noterez que seuls les 6 premiers niveaux d’un facteur se voient attribuer une forme automatiquement. Au delà de 6 symboles différents sur un même graphique, le résultat est souvent illisible. Il est possible d’ajouter plus de 6 symboles, mais cela demande de modifier la légende manuellement et concrètement nous n’en aurons jamais besoin. Lorsque plus de 6 séries doivent être distinguées, d’autres solutions bien plus pertinentes (par exemple les factets) devraient être utilisées. Comme pour la couleur, il est possible d’e spécifier’utiliser l’argument shape en tant que paramètre du graphique sans l’associer à une variable. Il faut alors fournir un code compris entre 0 et 24 : ggplot(data = alaska_flights, mapping = aes(x = dep_delay, y = arr_delay)) + geom_point(shape = 4) Figure 4.13: Utilisation de shape en tant que paramètre Notez qu’ici, ggplot() ne crée pas de légende : tous les points ont le même symbole, ce symbole n’est pas associé à une variable, une légende est donc inutile. Parmis les valeur possibles pour shape, les symboles 21 à 24 sont des symboles dont on peut spécifier séparément la couleur du contour, avec color et la couleur du fond avec fill : ggplot(data = alaska_flights, mapping = aes(x = dep_delay, y = arr_delay)) + geom_point(shape = 21, fill = &quot;steelblue&quot;, color = &quot;orange&quot;, alpha = 0.5) Figure 4.14: Utilisation de shape, color et fill N’hésitez pas à zoomer pour bien observer les points et comprendre ce qui se passe. Un conseil, faites des choix raisonnables ! Trop de couleurs n’est pas forcément souhaitable. Enfin, on peut ajuster la taille des symboles avec l’argument size. Tout comme il n’est pas possible d’associer une variable continue à shape, et il n’est pas conseillé d’associer une variable catégorielle nominale (c’est à dire un facteur non ordonné) à size. Associer une variable continue est en ravanche parfois utile : ggplot(data = alaska_flights, mapping = aes(x = dep_delay, y = arr_delay)) + geom_point(aes(size = arr_time), alpha = 0.1) Figure 4.15: Association d’une variable continue à la taille des symboles avec l’argument size Si l’over-plotting est ici très important (c’est pourquoi j’ai utilisé alpha), on constate néanmoins que les vols avec les retards les plus importants sont presque tous arrivés très tôt dans la journée (“500” signifie 5h00 du matin). Il s’agit probablement de vols qui devaient arriver dans la nuit, avant minuit, et qui sont finalement arrivés en tout début de journée, etnre 00h01 et 5h00 du matin. Comme pour les autres arguments, il est possible d’utiliser size avec une valeur fixe, la même pour tous les symboles, lorsque cet argument n’est pas associé à une variable. Enfin un conseil : évitez de trop surcharger vos graphiques. En combinant l’ensemble de ces arguments, il est malheureusement très facile d’obtenir des graphiques peu lisibles, ou contenant tellement d’information qu’ils en deviennent difficiles à déchiffrer. Faites preuve de modération : ggplot(data = alaska_flights, mapping = aes(x = dep_delay, y = arr_delay, size = arr_time)) + geom_point(alpha = 0.6, shape = 22, color = &quot;orange&quot;, fill = &quot;steelblue&quot;, stroke = 2) Figure 4.16: Sometimes, less is more! 4.3.6 Exercices À quoi sert l’argument stroke ? Avec le jeu de données diamonds, tapez le code permettant de créer le graphique 4.17 (Indice : affichez le tableau diamonds dans la console afin de voir quelles sont les variables disponibles). Figure 4.17: Prix de 53940 diamants en fonction de leur taille en carats et de leur couleur. Selon vous, à quoi sont dues les bandes verticales que l’on observe sur ce graphique ? 4.4 Les graphiques en lignes 4.4.1 Un nouveau jeu de données Les graphiques en ligne, ou “linegraphs” sont généralement utilisés lorsque l’axe des x porte une information temporelle, et l’axe des y une autre variable numérique. Le temps est une variable naturellement ordonnée : les jours, semaines, mois, années, se suivent naturellement. Les graphiques en lignes devraient être évités lorsqu’il n’y a pas une organisation séquentielle évidente de la variable portée par l’axe des x. Concentrons nous maintenant sur le tableau weather du package nycflights13. Explorez ce tableau en appliquant les méthodes vues dans le chapitre 3. N’oubliez pas de consultez l’aide de ce jeu de données. weather # A tibble: 26,115 x 15 origin year month day hour temp dewp humid wind_dir wind_speed &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 EWR 2013 1 1 1 39.0 26.1 59.4 270 10.4 2 EWR 2013 1 1 2 39.0 27.0 61.6 250 8.06 3 EWR 2013 1 1 3 39.0 28.0 64.4 240 11.5 4 EWR 2013 1 1 4 39.9 28.0 62.2 250 12.7 5 EWR 2013 1 1 5 39.0 28.0 64.4 260 12.7 6 EWR 2013 1 1 6 37.9 28.0 67.2 240 11.5 7 EWR 2013 1 1 7 39.0 28.0 64.4 240 15.0 8 EWR 2013 1 1 8 39.9 28.0 62.2 250 10.4 9 EWR 2013 1 1 9 39.9 28.0 62.2 260 15.0 10 EWR 2013 1 1 10 41 28.0 59.6 260 13.8 # ... with 26,105 more rows, and 5 more variables: wind_gust &lt;dbl&gt;, # precip &lt;dbl&gt;, pressure &lt;dbl&gt;, visib &lt;dbl&gt;, time_hour &lt;dttm&gt; Nous allons nous intéresser à la variable temp, qui contient un enregistrement de température pour chaque heure de chaque jour de 2013 pour les 3 aéroports de New York. Cela représente une grande quantité de données, aussi, nous nous limiterons aux températures observées entre le 1er et le 15 janvier, pour l’aéroport Newark uniquement. small_weather &lt;- weather %&gt;% filter(origin == &quot;EWR&quot;, month == 1, day &lt;= 15) La fonction filter() fonctionne sur le même principe que la fonction subset() vue lors du premier TP. Ici, nous demandons à R de créer un nouveau tableau de données, nommé small_weather, qui ne contiendra que les lignes correspondant à origin == &quot;EWR&quot;, et month == 1, et day &lt;= 15, c’est à dire les données météorologiques de l’aéroport de Newark pour les 15 premiers jours de janvier 2013. 4.4.2 Exercice Avec View(), consultez le tableau nouvellement créé. Expliquez pourquoi la variable time_hour identifie de manière unique le moment ou chaque mesure a été réalisée alors que ce n’est pas le cas de la variable hour. 4.4.3 La fonction geom_line() Les line graphs sont produits de la même façon que les nuages de points. Seul l’objet géométrique permettant de visualiser les données change. Au lieu d’utiliser geom_point(), on utilisera geom_line() : ggplot(data = small_weather, mapping = aes(x = time_hour, y = temp)) + geom_line() Figure 4.18: Températures horaires à l’aéroport de Newark entre le 1er et le 15 janvier 2013 Très logiquement, on observe des oscillations plus ou moins régulières qui correspondent à l’alternance jour/nuit. Notez l’échelle de l’axe des ordonnées : les températures sont enregistrées en degrés Farenheit. Nous connaissons maintenant 2 types d’objets geométriques : les points les les lignes. il est tout à fait possible d’ajouter plusieurs couches à un graphique, chacune d’elle correspondant à un objet geométrique différent : ggplot(data = small_weather, mapping = aes(x = time_hour, y = temp)) + geom_line() + geom_point() Figure 4.19: Températures horaires à l’aéroport de Newark entre le 1er et le 15 janvier 2013 Enfin, comme pour les points, il est possible de spécifier plusieurs caractéristiques esthétiques des lignes, soit en les associant à des variables, au sein de la fonction aes(), soit en les utilisant en guise de paramètres pour modifier l’aspect général. Les arguments les plus classiques sont une fois de plus color (ou colour) pour modifier la couleur des lignes, linetype pour modifier le type de lignes (continues, pointillées, tirets, etc), et size pour modifier l’épaisseur des lignes. Reprenons le jeu de données complet weather, et filtrons uniquement les dates comprises entre le premier et le 15 janvier, mais cette fois pour les 3 aéroports de New York : small_weather_airports &lt;- weather %&gt;% filter(month == 1, day &lt;= 15) Nous pouvons maintenant réaliser un “linegraph” sur lequel une courbe apparaîtra pour chaque aéroport. Pour cela, nous devons associer la variable origin à un attribut esthétique des lignes. Par exemple : ggplot(data = small_weather_airports, mapping = aes(x = time_hour, y = temp)) + geom_line(aes(color = origin)) Figure 4.20: Températures horaires des 3 aéroports de New York entre le 1er et le 15 janvier 2013 Ou bien : ggplot(data = small_weather_airports, mapping = aes(x = time_hour, y = temp)) + geom_line(aes(linetype = origin)) Figure 4.21: Températures horaires des 3 aéroports de New York entre le 1er et le 15 janvier 2013 Ou encore : ggplot(data = small_weather_airports, mapping = aes(x = time_hour, y = temp)) + geom_line(aes(color = origin, linetype = origin)) Figure 4.22: Températures horaires des 3 aéroports de New York entre le 1er et le 15 janvier 2013 4.4.4 À quel endroit placer aes() et les arguments color, size, etc. ? Jusqu’à maintenant, pour spécifier les associations entre certaines variables et les caractéristiques esthétiques d’un graphique, nous avons été amenés à utiliser la fonction aes() à 2 endroits distincts : au sein de la fonction ggplot() au sein des fonctions geom_XXX() Comment choisir l’endroit où renseigner aes() ? Pour bien comprendre, reprenons l’exemple du graphique 4.19 sur lequel nous avions ajouté 2 couches contenant chacune un objet géométrique différent (afin de gagner de la place, j’omets volontairement le nom es arguments data et mapping dans la fonction ggplot()) : ggplot(small_weather, aes(x = time_hour, y = temp)) + geom_line() + geom_point() Figure 4.23: Températures horaires à l’aéroport de Newark entre le 1er et le 15 janvier 2013 Voyons ce qui se passe si on associe la variable wind_speed à l’esthétique color, à plusieurs endroits du code ci-dessus. Comparez les trois syntaxes et observez les différences entre les 3 graphiques obtenus : ggplot(small_weather, aes(x = time_hour, y = temp, color = wind_speed)) + geom_line() + geom_point() Figure 4.24: Températures horaires et vitesse du vent à l’aéroport de Newark entre le 1er et le 15 janvier 2013 ggplot(small_weather, aes(x = time_hour, y = temp)) + geom_line(aes(color = wind_speed)) + geom_point() Figure 4.25: Températures horaires et vitesse du vent à l’aéroport de Newark entre le 1er et le 15 janvier 2013 ggplot(small_weather, aes(x = time_hour, y = temp)) + geom_line() + geom_point(aes(color = wind_speed)) Figure 4.26: Températures horaires et vitesse du vent à l’aéroport de Newark entre le 1er et le 15 janvier 2013 Vous l’aurez compris, lorsque l’on spécifie aes() à l’intérieur de la fonction ggplot(), les associations de variables et d’esthétiques sont appliquées à tous les objets géométriques, donc à toutes les autres couches. En revanche, quand aes() est spécifié dans une couche donnée, les réglages ne s’appliquent qu’à cette couche spécifique. En l’occurence, si le même réglage est spécifié dans la fonction ggplot() et dans une fonction geom_XXX(), c’est le réglage spécifié dans l’objet géométrique qui l’emporte : ggplot(small_weather, aes(x = time_hour, y = temp, color = wind_speed)) + geom_line(color = &quot;orange&quot;) + geom_point() Figure 4.27: Températures horaires et vitesse du vent à l’aéroport de Newark entre le 1er et le 15 janvier 2013 il est ainsi possible de spécifier des éléments esthétiques qui s’appliqueront à toutes les couches d’un graphique, et d’autres qui ne s’appliqueront qu’à une couche spécifique, qu’à un objet géométrique particulier. 4.5 Les histogrammes Un histogramme permet de visualiser la distribution d’une variable numérique continue. Contrairement aux deux types de graphique vus précédemment, il sera donc inutile de préciser la variable à associer à l’axe des ordonnées : R la cacule automatiquement pour nous lorsque nous faisons appel à la fonction geom_histogram() pour créer un objet géométrique “histogramme”. 4.5.1 L’objet geom_histogram() Si on reprend le jeu de données weather, on peut par exemple s’intéresser à la distribution des températures tout au long de l’année : ggplot(weather, aes(x = temp)) + geom_histogram() `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Figure 4.28: Histogramme des températures enregistrées en 2013 dans les 3 aéroports de New York On observe plusieurs choses : La distribution semble globalement bimodale avec un pic autour de 36-37 degrés farenheit (2 à 3 ºC) et un autre autour de 65-70 degrés farenheit (18-21 ºC). Les températures ont varié de 12 degrés farenheit (-11ºC) à 100 degrés farenheit (près de 38ºC). R nous avertit qu’une valeur non finie n’a pas pu être intégrée R nou indique qu’il a choisi de représenter 30 classes de températures (bins = 30). C’est la valeur par défaut. R nous conseille de choisir une valeur plus appropriée. Comme pour les nuages de points utilisant les symboles 21 à 24, il est possible de spécifier la couleur de remplissage des barres avec l’argument fill et la couleur du contour des barres avec l’argument color : ggplot(weather, aes(x = temp)) + geom_histogram(fill = &quot;steelblue&quot;, color = &quot;grey80&quot;) Figure 4.29: Utilisation des arguments fill et color pour modifier l’aspect de l’histogramme. 4.5.2 La taille des classes Par défaut, R choisit arbitrairement de représenter 30 classes. Ce n’est que rarement le bon choix, et il est souvent necessaire de tâtonner pour trouver le nombre de classes qui permet d’avoir une idée correcte de la distribution des données. Il est possible d’ajuster les caractéristiques des classes de l’histogramme de l’une des 3 façons suivantes : en ajustant le nombre de catégories avec bins en précisant la largeur des catégories avec binwidth en fournissant manuellement les limites des classes de tailles avec breaks ggplot(weather, aes(x = temp)) + geom_histogram(bins = 60, color = &quot;white&quot;) Figure 4.30: Modification du nombre de classes Ici, augmenter le nombre de classes à 60 permet de prendre conscience que la distribution n’est pas aussi lisse qu’elle en avait l’air. L’ajout d’une couche supplémentaire avec la fonction geom_rug() (“a rug”&quot; est un tapis en français) permet de prendre conscience que les données de température ne sont pas aussi continues qu’on pouvait le croire : ggplot(weather, aes(x = temp)) + geom_histogram(bins = 60, color = &quot;white&quot;) + geom_rug(alpha = 0.1) Figure 4.31: Ajout des données brutes sous forme de ‘tapis’ (rug) sous l’histogramme. Notez la transparence importante utilisée pour geom_rug. On constate que la précision des relevés de température n’est en fait que de quelques dixièmes de degrés. On peut également modifier la largeur des classes avec binwidth : ggplot(weather, aes(x = temp)) + geom_histogram(binwidth = 10, color = &quot;white&quot;) Figure 4.32: Modification de la largeur des classes avec binwidth Ici chaque catégorie recouvre 10 degrés farenheit. Enfin, il est possible de déterminer manuellement les limites des classes souhaitées avec l’argument breaks : ggplot(weather, aes(x = temp)) + geom_histogram(breaks = c(0, 10, 20, 50, 60, 70, 80, 105), color = &quot;white&quot;) Figure 4.33: Spécification manuelle des limites de classes de tailles (classes irrégulières) Vous constatez ici que les choix effectués ne sont pas très pertinents : toutes les classes n’ont pas la même largeur. Cela rend l’interprétation difficile. Il est donc vivement conseillé, pour spécifier breaks, de créer des suites régulières, comme avec la fonction seq() par exemple (consultez sont fichier d’aide et les exemples !) : limits &lt;- seq(from = 10, to = 105, by = 5) limits [1] 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 [20] 105 ggplot(weather, aes(x = temp)) + geom_histogram(breaks = limits, color = &quot;white&quot;) Figure 4.34: Un exemple d’utilisation de l’argument break Il est important que toute la gamme des valeurs de temp soit couverte par les limites des classes que nous avons définies, sinon, certaines valeurs sont omises et l’histogramme est donc incomplet/incorrect. Une façon de s’en assurer est d’afficher les résumé des données pour la colonne temp du jeu de données weather : summary(weather$temp) Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s 10.94 39.92 55.40 55.26 69.98 100.04 1 On voit ici que les températures varien de 10.94 à 100.04 degrés farenheit. Les classes que nous avons définies couvrent une plage de température plus large (de 10 à 105). Toutes les données sont donc bien intégrées à l’histogramme. 4.6 Les facets 4.6.1 facet_wrap() Nous l’avons indiqué plus haut, les facets permettent de scinder le jeux de données en plusieurs sous-groupes et de faire un graphique pour chacun des sous groupes. Ainsi, si l’on souhaite connaître la distribution des températures pour chaque mois de l’année 2013, plutôt que de faire ceci : ggplot(weather, aes(x = temp, fill = factor(month))) + geom_histogram(bins = 20, color = &quot;grey30&quot;) Figure 4.35: Distribution des températures avec visualisation des données mensuelles. qui produit un graphique certes assez joli, mais difficile à interpréter, mieux vaut faire ceci : ggplot(weather, aes(x = temp, fill = factor(month))) + geom_histogram(bins = 20, color = &quot;grey30&quot;) + facet_wrap(~factor(month), ncol = 3) Figure 4.36: Un exemple d’utilisation de facet_wrap() La couche supplémentaire créée avec facet_wrap permet donc de scinder les données en foncton d’une variable. Attention à la syntaxe ; il ne faut pas oublier le symbole ~ devant la variable que l’on souhaite utiliser pour scinder les données. Il va sans dire que la variable utilisée doit être catégorielle et non continue, c’est la raison pour laquelle j’utilise la notation factor(month) et non simplement month. Avec la fonction facet_wrap(), il est possible d’indiquer à R comment les différents graphiques doivent être agencés en spécifiant soit le nombre de colonnes souhaitées avec ncol, soit le nombre de lignes souhaitées avec nrow. 4.6.2 facet_grid() Une autre fonction nommée facte_grid permet d’agencer des sous graphique selon 2 variables catégorielles. Per exemple : ggplot(weather, aes(x = temp, fill = factor(month))) + geom_histogram(bins = 20, color = &quot;grey30&quot;) + facet_grid(factor(month) ~ origin) Figure 4.37: Un exemple d’utilisation de facet_grid() Ici, nous avons utilisé la variable month (transformée en facteur) et la variable origin pour créer un histogramme pour chaque combinaison des modalités de ces 2 variables. Il est donc possible de faire facilement des comparaisons des températures intermensuelles au sein d’un aéroport donné (en colonnes), ou de faire des comparaisons des températures observées le même mois dans plusieurs aéroports (en lignes). facet_grid() doit elle aussi être utilisée avec le symbole ~. Comme pour les indices d’un tableaux, on met à gauche du ~ la variable qui figurera en lignes, et à droite du ~ celle qui figurera en colonnes. Les arguments nrow et ncol ne peuvent donc pas être utilisés : c’est le nombre de niveaux de chaque variable catégorielle fournie à facet_grid() qui détermine le nombre de lignes et de colonnes du graphique. Vous devriez maintenant être convaincus de la puissance de la grammaire des graphiques. En utilisant un langage standardisé, et ajoutant des couches une à une sur un graphique, il est posible d’obtenir rapidement des visualisations très complexes et néanmoins très claires, qui font apparaître des srtuctures intéressantes dans nos données (des tendances, des groupes, des similitudes, des liaisons, des différences, etc). 4.6.3 Exercices Examinez la figure 4.37. Quels éléments nouveaux ce graphiques nous apprend-il par rapport au graphique 4.34 ci-dessus ? Comment le “faceting” nous aide-t’il à visualiser les relations entre 2 (ou 3) variables ? À quoi correspondent les numéros 1 à 12 ? À quoi correspondent les chiffres 25, 50, 75, 100 ? À quoi correspondent les chiffres 0, 100, 200, 300 ? Observez les échelles des axes x et y pour chaque sous graphique. Qu’on-t’elles de particulier ? En quoi est-ce utile ? La variabilité des températures est-elle plus importante entre les aéroports, entre les mois, ou au sein des mois ? Expliquez votre réflexion. 4.7 Les boîtes à moustaches ou boxplots 4.7.1 Création de boxplots et informations apportées Commençons par créer un boxplot pour comparer les températures mensuelles comme nous l’avons fait plus haut avec des histogrammes : ggplot(weather, aes(x = month, y = temp)) + geom_boxplot() Warning: Continuous x aesthetic -- did you forget aes(group=...)? Warning: Removed 1 rows containing non-finite values (stat_boxplot). Figure 4.38: Un boxplot for peu utile… Comme précédemment, R nous avertit qu’une observation n’a pas été intégrée (en raison d’une donnée manquante). Mais il nous dit aussi que x (pour nous, la variable month) est continue, et que nous avons probablement oublié de spécifier des groupes. En effet, les boxplots sont généralement utilisés pour examiner la distribution d’une variable numérique, pour chaque niveau d’une variable catégorielle (un facteur). Il nous faut donc, ici encore, transformer month en facteur car dans notre tableau de départ, cette variable est considérée comme une variable numérique continue : ggplot(weather, aes(x = factor(month), y = temp)) + geom_boxplot() Figure 4.39: Boxplot des températures mensuelles Les différents éléments d’un boxplot, sont les suivants : la limite inférieure de la boîte correspond au premier quartile : 25% des données de l’échantillon sont situées sous cette valeur la limite supérieure de la boîte correspond au troisième quartile : 25% des données de l’échantillon sont situées au-dessus de cette valeur le segment épais à l’intérieur de la boîte corrspond au second quartile : c’est la médiane de l’échantillon. 50% des données de l’échantillon sont situées au dessus de cette valeur, et 50% au dessous. la heuteur de la boîte correspond à ce que l’on appelle l’étendue inter-quartile ou Inter Quartile Range (IQR) en anglais. On trouve dans cette boîte 50% des observations de l’échantillon. C’est une mesure de la dispersion des 50% des données les plus centrales. Une boîte plus allongée indique donc une plus grande dispersion. moustaches correspondent à des valeurs qui sont en dessous du premier quartile (pour la moustache du bas) et au dessus du troisième quartile (pour la moustache du haut). La règle utilisée dans R est que ces moustaches s’étendent usqu’aux valeurs minimales et maximales de l’échantillon, mais elles ne peuvent en aucun cas s’étendre au-delà de 1,5 fois la hauteur de la boîte (1,5 fois l’IQR) vers le haut et le bas. Si des points apparaissent au-delà des moustaches (vers le haut ou le bas), ces points sont appelés “outliers”. Ce sont des points qui s’éloignent du centre de la distribution de façon importante puisqu’ils sont au-delà de 1,5 fois l’IQR de part et d’autres du premier ou du troisième quartile. Il peut s’agir d’anomalies de mesure, d’anomalie de saisie de données, ou tout simplement, d’enregistrement tout à fait valides mais extrêmes. J’attire votre attention que la définition de ces outliers est relativement arbitraire. Nous pourrions faire le choix d’étendre les moustaches jusqu’à 1,8 fois l’IQR (ou 2, ou 2,5), nous observerions alors beaucoup moins d’outliers. D’une façons générale, la longueur des moustaches renseigne sur la variabilité des données en dehors de la zone centrale. Plus elles sont longues, plus la variabilité est importante. 4.7.2 L’intervalle de confiance à 95% de la médiane On peut également aujouter une encoche autour de la valeur de médiane en ajoutant l’argument notch = TRUE à la fonction geom_boxplot() : ggplot(weather, aes(x = factor(month), y = temp)) + geom_boxplot(notch = TRUE) Figure 4.40: Boxplot des températures mensuelles. Les intervalles de confiance à 95% de la médiane sont affichés. Comme l’indique la légende de la figure 4.40, cette encoche correspond à l’etendue de l’intervalle de confiance à 95% de la médiane. Pour chaque échantillon, nous espérons que la médiane calculée soit le reflet fidèle de la vraie valeur de médiane de la population. Mais il sera toujours impossible d’en avoir la certitude absolue. Le mieux que l’on puisse faire, c’est quantifier l’incertitude. L’intervalle de confiance nous indique qu’il ya de bonnes chances que la vraie valeur de médiane de la population générale (qui restera à jamais inconnue) a de bonnes chances de se trouver dans cet intervalle. Ici, les encoches sont très étroites car les données sont abondantes. il y a donc peu d’incertitude, ce qui est une bonne chose. Nous reviendrons sur cette notion importante à la fin des TP de biométrie 2 ou en biométrie 3, car ce type de graphique nous permettra d’anticiper sur les résultats des tests de comparaisons de moyennes. 4.7.3 Une autre façon d’examiner des distributions Dernière chose concernant les boxplots : il s’agit d’une représentation graphique très proche de l’histogramme. Pour vous en convaincre, je représente à la figure 4.41 ci-dessous uniquement les temperatures du mois de novembre, avec 3 types d’objets géométriques différents : un histogramme, un boxplot, et un nuage de points. Figure 4.41: Distribution des températures de Novembre 2013 Nous avons donc, à gauche un histogramme pour les températures de novembre (j’ai permuté les axes pour que y porte la température pour les 3 graphiques), au centre, un boxplot pour ces mêmes données, et à droite, les données brutes, sous la forme d’un nuage de point créé avec geom_jitter(). On voit bien que ces 3 représentations graphiques sont similaires. Toutes rendent compte du fait que les températures de Novembre sont majoritairement comprises entre 35 et 52 degrés farenheit. Au-delà de cette fourchette (au-dessus comme en-dessous) les observations sont plus rares. Le nuage de points affiche toutes les données. C’est donc lui le plus complet mais pas forcément le plus lisible. Les points sont en effet très nombreux et la lecture du graphique peut s’en trouver compliquée. L’histogramme simplifie les données en les regroupant dans des classes. C’est une sorte de résumé des données. On constate cependant toujours la présence de 2 pics qui correspondent aux zones plus denses du nuage de points. Le boxplot enfin synthétise encore plus ces données. Elles sont résumées par 7 valeurs seulement : le minimum, le maximum, les 3 quartiles, et les bornes de l’intervalle de confiance à 95% de la médiane. C’est une représentation très synthétique qui nous permet de comparer beaucoup de catégories côte à côte (voir la figure 4.40 un peu plus haut), mais qui est forcément moins précise qu’un histogramme. Vous noterez toutefois que la boîte du boxplot recouvre en grande partie la zone des 2 pics de l’histogramme. En outre, sur la figure 4.40, la tendance générale est très visible : il fait plus chaud en été qu’en hiver (étonnant non ?). 4.7.4 Pour conclure Les boîtes à moustaches permettent donc de comparer et contraster la distribution d’une variable quantitative pour plusieurs niveaux d’une variable catégorielle. On peut voir où la médiane tombe dans les différents groupes en observant la position de la ligne centrale dans la boîte. Pour avoir une idée de la dispersion de la variable au sein de chaque groupe, regardez à la fois la hauteur de la boîte et la longueur des moustaches. Quand les moustaches s’étendent loin de la boîte mais que la boîte est petite, cela signifie que la variabilité des valeurs proches du centre de la distribution est beaucoup plus faible que la variabilité des valeurs extrêmes. Enfin, les valeurs extrêmes ou aberrantes sont encore plus faciles à détecter avec une boîte à moustaches qu’avec un histogramme. 4.8 Les diagrammes bâtons Références "],
["tidyr.html", "5 (Ar)ranger des données avec tidyr", " 5 (Ar)ranger des données avec tidyr "],
["wrangling.html", "6 Tripatouiller les données avec dplyr", " 6 Tripatouiller les données avec dplyr "],
["references.html", "Références", " Références "]
]
